{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dilshad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\dilshad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dilshad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dilshad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dilshad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dilshad\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dilshad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dilshad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from creme import metrics\n",
    "import creme\n",
    "from creme import naive_bayes\n",
    "from creme import feature_extraction\n",
    "from creme import compose\n",
    "import math\n",
    "import pickle\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "# stopwords.words('english')\n",
    "# string.punctuation\n",
    "ps = PorterStemmer()\n",
    "# ps.stem('worries')\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "# with open('predict-doc.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesse_df(df):\n",
    "    df = df.dropna()\n",
    "    df.duplicated().sum()\n",
    "    df = df.drop_duplicates(keep='first')\n",
    "    df['transformed_content'] = df['content'].apply(transform_text)\n",
    "    processed_df = df[df['content'].str.len() >= 1000]\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business Documents.csv' 'Creative Documents.csv'\n",
      " 'Educational Documents.csv' 'Financial Documents.csv'\n",
      " 'Govt Documents.csv' 'Legal Documents.csv' 'Medical Documents.csv'\n",
      " 'News Documents.csv' 'Scientific Documents.csv' 'Technical Documents.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the train folder\n",
    "train_folder_path = './db/train/'\n",
    "\n",
    "# Get a list of all filenames in the train folder\n",
    "filenames = os.listdir(train_folder_path)\n",
    "\n",
    "# Filter out only the files (excluding directories)\n",
    "filenames = [filename for filename in filenames if os.path.isfile(\n",
    "    os.path.join(train_folder_path, filename))]\n",
    "\n",
    "# Convert the list of filenames to a NumPy array\n",
    "filenames_array = np.array(filenames)\n",
    "\n",
    "# Display the filenames array\n",
    "print(filenames_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Message-ID: &lt;25140503.1075855687800.JavaMail.e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Message-ID: &lt;19034252.1075855687825.JavaMail.e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Message-ID: &lt;719350.1075855687850.JavaMail.eva...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Message-ID: &lt;10523086.1075855687873.JavaMail.e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Message-ID: &lt;15816310.1075855374294.JavaMail.e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>Message-ID: &lt;6521706.1075855374316.JavaMail.ev...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Message-ID: &lt;21543395.1075855374340.JavaMail.e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Message-ID: &lt;25363451.1075855374674.JavaMail.e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>Subject: Inviting quotation\\nDear Sir,\\nWe are...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1016 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  category\n",
       "0     Message-ID: <24216240.1075855687451.JavaMail.e...       NaN\n",
       "1     Message-ID: <25140503.1075855687800.JavaMail.e...       NaN\n",
       "2     Message-ID: <19034252.1075855687825.JavaMail.e...       NaN\n",
       "3     Message-ID: <719350.1075855687850.JavaMail.eva...       NaN\n",
       "4     Message-ID: <10523086.1075855687873.JavaMail.e...       NaN\n",
       "...                                                 ...       ...\n",
       "1011  Message-ID: <15816310.1075855374294.JavaMail.e...       NaN\n",
       "1012  Message-ID: <6521706.1075855374316.JavaMail.ev...       NaN\n",
       "1013  Message-ID: <21543395.1075855374340.JavaMail.e...       NaN\n",
       "1014  Message-ID: <25363451.1075855374674.JavaMail.e...       NaN\n",
       "1015  Subject: Inviting quotation\\nDear Sir,\\nWe are...       NaN\n",
       "\n",
       "[1016 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./db/train/'+filenames_array[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Medical Documents.csv started\n",
      "                                    transformed_content         category\n",
      "0     glaucoma group diseas damag eye optic nerv res...  Medical Records\n",
      "1     nearli million peopl glaucoma lead caus blind ...  Medical Records\n",
      "2     symptom glaucoma glaucoma develop one eye comm...  Medical Records\n",
      "3     although glaucoma cure usual control treatment...  Medical Records\n",
      "14    high blood pressur common diseas blood flow bl...  Medical Records\n",
      "...                                                 ...              ...\n",
      "1017  key point colorect cancer diseas malign cancer...  Medical Records\n",
      "1019  key point transit cell cancer renal pelvi uret...  Medical Records\n",
      "1021  test examin abdomen kidney use detect find dia...  Medical Records\n",
      "1023  key point transit cell cancer renal pelvi uret...  Medical Records\n",
      "1024  key point differ type treatment patient transi...  Medical Records\n",
      "\n",
      "[491 rows x 2 columns]\n",
      "Accuracy: 100.00%\n",
      "6 Medical Documents.csv successful ------------------------------\n",
      "7 News Documents.csv started\n",
      "                                    transformed_content       category\n",
      "0     strong sanya china china effort lift local con...  News Articles\n",
      "1     strong new anil ambani relianc group never mad...  News Articles\n",
      "4     strong oil price inch toward 50 barrel monday ...  News Articles\n",
      "6     strong new york major confer aim build linkag ...  News Articles\n",
      "7     strong gold rose earli wednesday close previou...  News Articles\n",
      "...                                                 ...            ...\n",
      "4228  india open sky competit india allow domest com...  News Articles\n",
      "4229  yuko bankruptci us russian author abid us cour...  News Articles\n",
      "4230  survey confirm properti slowdown govern figur ...  News Articles\n",
      "4231  high fuel price hit ba profit british airway b...  News Articles\n",
      "4232  us trade gap hit record 2004 gap us export imp...  News Articles\n",
      "\n",
      "[3478 rows x 2 columns]\n",
      "Accuracy: 99.97%\n",
      "7 News Documents.csv successful ------------------------------\n",
      "8 Scientific Documents.csv started\n",
      "                                  transformed_content  \\\n",
      "8   studi investig human immun respons begun chara...   \n",
      "9   refer walter william 2019 evolut mechan behavi...   \n",
      "11  ell build block live thing type cell play diff...   \n",
      "12  research interest stem cell studi stem cell he...   \n",
      "13  abstract find hadamard matrix among possibl bi...   \n",
      "16  result assumpt sp current version imprint sp b...   \n",
      "18  experiment method experiment method similar pr...   \n",
      "\n",
      "                     category  \n",
      "8   Scientific Research Paper  \n",
      "9   Scientific Research Paper  \n",
      "11  Scientific Research Paper  \n",
      "12  Scientific Research Paper  \n",
      "13  Scientific Research Paper  \n",
      "16  Scientific Research Paper  \n",
      "18  Scientific Research Paper  \n",
      "Accuracy: 71.43%\n",
      "8 Scientific Documents.csv successful ------------------------------\n",
      "9 Technical Documents.csv started\n",
      "                                  transformed_content           category\n",
      "0   legal inform copyright 2022 hp develop compani...  Technical Manuals\n",
      "1   best practic set regist comput recommend follo...  Technical Manuals\n",
      "2   3 connect network comput travel wherev go even...  Technical Manuals\n",
      "3   standard legisl countri worldwid enact regul i...  Technical Manuals\n",
      "5   complet guid use camera see refer manual 0 iv ...  Technical Manuals\n",
      "9   notic part manual includ nikon held liabl prod...  Technical Manuals\n",
      "10  notic custom batteri charger import safeti ins...  Technical Manuals\n",
      "11  notic concern prohibit copi reproduct note sim...  Technical Manuals\n",
      "18  1 introduct maintain accur log book tediou aff...  Technical Manuals\n",
      "19  upload data gp log book devic success creat ac...  Technical Manuals\n",
      "Accuracy: 90.00%\n",
      "9 Technical Documents.csv successful ------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,file in enumerate(filenames_array):\n",
    "    if i<=6:\n",
    "        continue\n",
    "    print(i, file, 'started')\n",
    "    df = pd.read_csv('./db/train/'+file)\n",
    "\n",
    "    if i==5:\n",
    "        del df['Unnamed: 2']\n",
    "        del df['Unnamed: 3']\n",
    "        del df['Legal Document']\n",
    "\n",
    "    # df.rename(columns={'Content': 'content',\n",
    "    #           'Category': 'category'}, inplace=True)\n",
    "    if file == 'Business Documents.csv':\n",
    "        df.loc[:, 'category'] = 'Business Documents'\n",
    "\n",
    "    new_df = preprocesse_df(df)\n",
    "\n",
    "    transformed_df = new_df[['transformed_content', 'category']]\n",
    "    print(transformed_df.shape)\n",
    "\n",
    "    # message_train, message_test = train_test_split(transformed_df)\n",
    "\n",
    "    messages_train = transformed_df.to_records(index=False)\n",
    "    # messages_test = message_test.to_records(index=False)\n",
    "\n",
    "    # model = compose.Pipeline(\n",
    "    #     ('tokenize', feature_extraction.BagOfWords(lowercase=False)),\n",
    "    #     ('nb', naive_bayes.MultinomialNB(alpha=1))\n",
    "    # )\n",
    "\n",
    "    # Load the model from the file\n",
    "    with open('predict-doc2.pkl', 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "\n",
    "    model = loaded_model\n",
    "\n",
    "\n",
    "\n",
    "    metric = metrics.Accuracy()\n",
    "    # Training the model row by row\n",
    "    for content, category in messages_train:\n",
    "        model = model.fit_one(content, category)\n",
    "        y_pred = model.predict_one(content)\n",
    "        metric = metric.update(category, y_pred)\n",
    "    print(metric)\n",
    "\n",
    "    # # test Data Accuracy\n",
    "    # test_metric = metrics.Accuracy()\n",
    "    # for content, category in messages_test:\n",
    "    #     y_pred = model.predict_one(content)\n",
    "    #     test_metric = metric.update(category, y_pred)\n",
    "    # print(test_metric)\n",
    "\n",
    "\n",
    "    with open('predict-doc2.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    print(i, file, 'successful ------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
